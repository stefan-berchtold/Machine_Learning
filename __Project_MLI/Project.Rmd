---
title: "MSc.IDS - Machine Learning I"
subtitle: "Report of Group Work 'House Sales in King County, USA'"
author: "Stefan Berchtold, Georg Oberer"
date:
- "`r format(Sys.Date(), '%d.%m.%Y')` "
output: 
  html_document:
    theme: yeti
    toc: true
    toc_float:
      collapsed: false
    toc_depth: 2
    code_folding: hide
    
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>

# Purpose of the report

The report should show the lecturers our knowledge achieved during the course "Machine Learning I" at the University of Applied Sciences and Arts. Therefore the authors are going to conduct several analyses seen in the course using real data. Which dataset is used is the responsibility of the others but it has to fullfill following requirements:

 - Moderate size (N = [10^3, 10^5], 10-20 predictors)
 - Real data
 - Must contain both: Continous and categorical variables 
 - At least one categorical variable must have more than two levels


The following chapters document the process of:

 -
 -
 -


# Dataset


The dataset contains the follwoing variables:

 - id: Unique ID for each home sold
 
 - date: Date of the home sale
 - price: Price of each home sold
 - bedrooms: Number of bedrooms
 - bathrooms: Number of bathrooms, where .5 accounts for a room with a toilet but no shower
 - sqft_living: Square footage of the apartments interior living space
 - sqft_lot: Square footage of the land space
 - floors: Number of floors
 - waterfront: A dummy variable for whether the apartment was overlooking the waterfront or not
 - view: An index from 0 to 4 of how good the view of the property was
 - condition: An index from 1 to 5 on the condition of the apartment
 - grade: An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design
 - sqft_above: The square footage of the interior housing space that is above ground level
 - sqft_basement: The square footage of the interior housing space that is below ground level
 - yr_built: The year the house was initially built
 - yr_renovated: The year of the houseâ€™s last renovation
 - zipcode: What zipcode area the house is in
 - lat: Lattitude
 - long: Longitude
 - sqft_living15: The square footage of interior housing living space for the nearest 15 neighbors
 - sqft_lot15: The square footage of the land lots of the nearest 15 neighbors



```{r}
data <- read.csv("kc_house_data.csv", sep = ",", header = TRUE)
str(data)
summary(data)

```
The variable id is just a random generated number so we can remove that.
condition, view, waterfront, grade and condition are categorical variables so they have to be converted accordingly 

```{r}
data <- read.csv("kc_house_data.csv", sep = ",", header = TRUE, colClasses = c("view" = "factor", "waterfront" = "factor", "condition" = "factor", "grade" = "factor"), as.is = TRUE)


```





```{r }
df <- data[, c(-1, -2)]

unique(df$sqft_basement)

```

# Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```





```{r}
model <- lm(df$price~., data = df)
summary(model)
```


```{r}
model1 <- lm(df$price~.-sqft_basement, data = df)
summary(model1)


```




```{r}

RSS <- c(crossprod(model$residuals))
MSE <- RSS / length(model$residuals)
RMSE <- sqrt(MSE)
print(RMSE)


```




# Support Vector Machines



```{r}
set.seed(134616)
library(e1071)
library(caret)
library(doParallel)


indexes <- createDataPartition(df$price, p = .9, list = F)
train <- df[indexes, ]
test <- df[-indexes, ]

svmfit_reg <- svm(price~., data = train, kernel = "linear", cost = 0.1 )

```


```{r}
pred <- predict(svmfit_reg, test)
x <- 1:length(test$price)
plot(x, test$price, pch=18, col="red")
lines(x, pred, lwd="1", col="blue")
```


```{r}
print(RMSE(pred, test$price)/mean(df$price))
rsquared <- cor(pred,test$price)^2
print(rsquared)
r_squared_adj <- 1-((1-rsquared)*(nrow(df)-1)/(nrow(df)-ncol(df)-1))
print(r_squared_adj)
```




```{r}
tuned_model <- tune(svm, price~., data = train, kernel = "linear", ranges = list(epsilon = seq(0,1,0.2),cost = c(0.1,1,5))

bestmodel <- tuned_model$best.model
summary(bestmodel)

```



```{r}
svmfit_reg1 <- svm(price~., data = train, kernel = "linear", cost = 5, epsilon = 0.1)

```




```{r}

pred1 <- predict(svmfit_reg1, test)
x <- 1:length(test$price)
plot(x, test$price, pch=18, col="red")
lines(x, pred1, lwd="1", col="blue")



```




```{r}

print(RMSE(pred1, test$price)/mean(df$price))
rsquared <- cor(pred1,test$price)^2
print(rsquared)
r_squared_adj <- 1-((1-rsquared)*(nrow(databla)-1)/(nrow(databla)-ncol(databla)-1))
print(r_squared_adj)

```




# Neural Network 


```{r}
library(nnet)
library(gamlss.add)
library(dplyr)
library(ggplot2)
library(caret)

```


```{r}
set.seed(123)
set.seed(123)
indices <- createDataPartition(as.numeric(databla$price), p = 0.8, list = FALSE)
train <- databla %>% slice(indices)
test <- databla %>% slice(-indices)


```


```{r}
str(indices)
```


```{r}
tuGrid <- expand.grid(.layer1=c(1:4), .layer2=c(0,2), .layer3=c(0))
trCtrl <- trainControl(
method = 'repeatedcv',
number = 5,
repeats = 10,
returnResamp = 'final'
)
models <- train(
x = databla %>% select(-price, -id, -date,),
y = databla %>% pull(price),
method = 'neuralnet', metric = 'RMSE',
linear.output = TRUE,
# be careful, does only work on x!
preProcess = c('center', 'scale'),
tuneGrid = tuGrid,
trControl = trCtrl
)


```




```{r}
plot(models)
```

